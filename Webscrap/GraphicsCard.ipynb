{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping for Graphicscard dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL which I want to scraping, Take the URL in a Variable\n",
    "\n",
    "my_url = \"https://www.newegg.com/global/in/Product/ProductList.aspx?Submit=ENE&N=-1&IsNodeId=1&Description=graphics%20card&bop=And&Page=1&PageSize=36&order=BESTMATCH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Connection and  Grab the URL(HTTPResponse)\n",
    "uClient = uReq(my_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the URL is correct or not\n",
    "uClient.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HTTPResponse and store raw text data into a variable\n",
    "page_html = uClient.read()\n",
    "\n",
    "# Close the Connection\n",
    "uClient.close()\n",
    "\n",
    "page_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the raw text into html by the help of beautifulsoup\n",
    "\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "\n",
    "page_soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup.h1                        # Set the text contents into html format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the page encode format\n",
    "page_soup.encode_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of Find all \n",
    "# Grab each product\n",
    "containers = page_soup.find_all('div',{\"class\" : \"item-container \"})\n",
    "print(type(containers), len(containers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the nth Item from the result set\n",
    "first_GCard = containers[15]\n",
    "first_GCard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_GCard.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_GCard.div.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_GCard.div.div.find(\"span\", {\"class\" : \"item-rating-num\"}).text.replace('(', \"\").replace(')', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_GCard.div.find(\"li\", {\"class\" :\"price-current\"}).text.strip(' \\xa0\\r\\n\\n-').replace('\\xa0\\r\\n', '').replace('\\xa0','').replace(',','').strip(' ').replace('\\n\\n–','').replace('\\n–','').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write result set into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:\\DataAnalysis\\Data\\webscrap\\graphicard.csv\"\n",
    "f= csv.writer(open(filename,'w', encoding=\"utf-8\"))\n",
    "header = 'Brand, Product_Title,Reviewers,Price \"\\n\"'\n",
    "f.writerow(header)\n",
    "\n",
    "for container in containers:\n",
    "    BrandName = container.div.div.a.img['title']\n",
    "    Product_Title = container.find('a', {\"class\" : \"item-title\"}).get_text()\n",
    "    Reviewers = container.div.span.text\n",
    "    Price = container.find(\"li\", {\"class\" : \"price-current\"}).get_text().strip()\n",
    "    #print(BrandName,Product_Title,Reviewers,Price)\n",
    "    f.writerow(BrandName.replace(',','') + \",\" + Product_Title.replace(\",\", \" \") + \",\" +Reviewers+ \",\" + Price+ \"\\n\")\n",
    "    # f.writerows([BrandName.replace(',',''),Product_Title,Reviewers,Price])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to inspect each element and pull the Data from the result set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for container in containers:\n",
    "    BrandName = container.div.div.a.img['title'].replace(',', '')\n",
    "    print(BrandName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for container in containers:\n",
    "    Product_Title = container.find('a', {\"class\" : \"item-title\"}).get_text().replace(\",\", \" \")\n",
    "    print(Product_Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details \n",
    "for rating in containers:\n",
    "    Reviewers = rating.div.span.text.replace(\"(\", \"\").replace(\")\",\"\")\n",
    "    print(Reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for price in containers:\n",
    "    Amount = price.find(\"li\", {\"class\" : \"price-current\"}).get_text().strip(' \\n\\t\\r').replace(\"₹\",\"\").replace(\",\",\"\").replace(\"–\",\"\").replace('$', \"\").replace('RRP','')\n",
    "    \n",
    "    print(Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the result set into CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"C:\\DataAnalysis\\Data\\webscrap\\GraphisCard.csv\"\n",
    "f = open(file, 'w', encoding='utf-8')\n",
    "header = (\"Brand_Title, Prod_Title, Price, Reviewers \\n\")\n",
    "f.write(header)\n",
    "for item in containers:\n",
    "    Brand_Title = item.div.div.a.img['title'].replace(',', '').strip(' \\t\\n\\r')\n",
    "    Prod_Title = item.find('a', {\"class\" : \"item-title\"}).get_text().replace(\",\", \"\").strip(' \\t\\n\\r')\n",
    "    Amount = item.div.find(\"li\", {\"class\" :\"price-current\"}).text.strip(' \\xa0\\r\\n\\n-').replace('\\xa0\\r\\n', '').replace('₹ ','').replace('\\n–','').replace(',','').replace(\"-\",\"\").replace('\\xa0','').replace('\\n','').strip(' ')\n",
    "    NoOfReviews = item.div.span.text.replace(\"(\", \"\").replace(\")\",\"\").strip(' \\t\\n\\r')\n",
    "    print(Brand_Title + \", \" + Prod_Title + \", \" + Amount+ \", \" + NoOfReviews)\n",
    "    f.write(Brand_Title + \", \" + Prod_Title + \", \" + Amount + \", \" + NoOfReviews + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
