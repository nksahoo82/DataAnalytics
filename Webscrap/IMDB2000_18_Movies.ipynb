{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to scrap movies details from 2000 to 2008\n",
    "\n",
    "##### 1. We only scrap first 4 pages of each year\n",
    "#### 2. We only scrap which has MetaScore value\n",
    "#### 3. We are scraping Movie details from 2000 to 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setaps to scrap the data for above condition\n",
    "\n",
    "1. Declaring all the variables.\n",
    "2. Preparing the monitoring tool.\n",
    "3. Loop through the years_url list to vary the release_date parameters of the URL\n",
    "4. For each element in years_url, loop through the pages list vary to vary the page parameter of the URL.\n",
    "5. make the urlopen request with in the page loop, \n",
    "6. pause the loop for a time interval between 8 and 15 sec.\n",
    "7. Monitor each request and its status code.\n",
    "8. Through a warning for non-200 status code.\n",
    "9. Break the loop if the number of requests is greater than expected.\n",
    "10. convert the response's HTML content to Beautifulsoup object.\n",
    "11. Extract all movie containers fromBeautifulsoup object.\n",
    "12. Loop through all these containers.\n",
    "13. Extract the data if Movie has MetaScore value.\n",
    "14. print the data into console\n",
    "15. Write the data into csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as opn_url\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import time\n",
    "from random import randint\n",
    "from time import time\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the variable declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request : 72; Frequency : 0.06661890306395062 requests/s\n"
     ]
    }
   ],
   "source": [
    "Titles = []\n",
    "ReleaseYears = []\n",
    "Runtimes = []\n",
    "Genres = []\n",
    "Ratings = []\n",
    "MetaScores = []\n",
    "Votes = []\n",
    "\n",
    "filename = \"C:\\DataAnalysis\\Data\\webscrap\\MovieList2000_18.csv\"\n",
    "f= open(filename,'w', encoding=\"utf-8\")\n",
    "header = 'Title, ReleaseYear, Runtime, Genres, Rating, MetaScore,Votes \\n'\n",
    "f.write(header)\n",
    "\n",
    "# Preparing the Monitoring of the loop\n",
    "start_time = time()\n",
    "requests = 0\n",
    "\n",
    "# Declare the years range in a list\n",
    "years_url = [str(yrs) for yrs in range(2000,2018)]\n",
    "\n",
    "# Specify the page range(4) for each year \n",
    "pages = [str(p) for p in range(1,5)]\n",
    "\n",
    "# For every year in the interval 2000 to 2018\n",
    "for yr_url in years_url:\n",
    "    \n",
    "    #page range 4, for each year\n",
    "    for page in pages:\n",
    "        \n",
    "        # Make a request for URL\n",
    "        imdb_url = 'http://www.imdb.com/search/title?release_date=' +yr_url+ '&page=' +page+ 'ref_=adv_prv'\n",
    "        \n",
    "        # pause the loop\n",
    "        sleep(randint(8,15))\n",
    "        \n",
    "        # Monitor the request\n",
    "        requests +=1\n",
    "        elapsed_time = time() - start_time\n",
    "        print('Request : {}; Frequency : {} requests/s'.format(requests, requests/elapsed_time))\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        # Throw warn for non-200 status code\n",
    "        url_response = opn_url(imdb_url)\n",
    "        if url_response.status !=200:\n",
    "            warn('Request : {}; StatusCode : {}'.format(requests, url_response.status)) \n",
    "        \n",
    "        # Break the loop if number of request greater than expected\n",
    "        if requests > 72:\n",
    "            warn('Number of request is greater than expected')\n",
    "            break\n",
    "        # Read the HTTP response and store contents inti page_html\n",
    "        page_html = url_response.read()\n",
    "        \n",
    "        # Parse the HTTPResponse contents into html format using beautifulsoup\n",
    "        \n",
    "        page_soup = bs(page_html, 'html.parser')\n",
    "        \n",
    "        # Select all 50 movies from a single page and store into containers\n",
    "        containers = page_soup.find_all('div', {'class' : 'lister-item-content'})\n",
    "        \n",
    "        # Extract the movie data for 50 movies from the containers\n",
    "        for item in containers:\n",
    "            if item.find('span', class_ ='metascore') is not None:\n",
    "                \n",
    "                title = item.h3.a.text.replace(',','')\n",
    "                Titles.append(title)\n",
    "                \n",
    "                release_yr = item.find('span', class_ ='lister-item-year').text.replace('(','').replace(')','')\n",
    "                ReleaseYears.append(release_yr)\n",
    "                \n",
    "                duration = item.find('span', {'class' : 'runtime'}).text\n",
    "                Runtimes.append(duration)\n",
    "                \n",
    "                genre = item.find('span', {'class' : 'genre'}).text.replace('\\n', '').replace(',', '|').strip()\n",
    "                Genres.append(genre)\n",
    "                \n",
    "                rating = item.strong.text\n",
    "                Ratings.append(float(rating))\n",
    "                \n",
    "                meta = item.find('span', class_ ='metascore').text.strip()\n",
    "                MetaScores.append(meta)\n",
    "                \n",
    "                vote = item.find('span', {'name' : 'nv'}).text.replace(',', '')\n",
    "                Votes.append(vote)\n",
    "                \n",
    "                f.write(title + \", \" + release_yr + \", \" + duration + \", \" + genre + \", \" + rating + \", \" + meta + \",\" + vote + \"\\n\")\n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
